import torch
import numpy as np
from sklearn.preprocessing import StandardScaler
from torch.utils.data import Dataset, DataLoader
import math
import torch.nn as nn
from flask import Flask, request, jsonify

class TimeSeriesTransformer(nn.Module):
    def __init__(self, input_size, embed_dim, num_heads, num_layers, dim_feedforward, dropout):
        super(TimeSeriesTransformer, self).__init__()
        assert embed_dim % num_heads == 0, "embed_dim must be divisible by num_heads"

        self.embedding = nn.Linear(input_size, embed_dim)
        self.positional_encoding = PositionalEncoding(embed_dim)
        self.transformer = nn.Transformer(
            d_model=embed_dim,
            nhead=num_heads,
            num_encoder_layers=num_layers,
            num_decoder_layers=num_layers,
            dim_feedforward=dim_feedforward,
            dropout=dropout
        )
        self.fc = nn.Linear(embed_dim, 2)
        self.softmax = nn.Softmax(dim=1)

    def forward(self, x):
        x = self.embedding(x)
        x = self.positional_encoding(x)
        x = x.permute(1, 0, 2)  # Transformer expects (seq_len, batch, embed_dim)
        output = self.transformer(x, x)
        output = output[-1, :, :]  # Take the output of the last time step
        output = self.fc(output)
        output = self.softmax(output)  # Apply softmax to get probabilities
        return output

class PositionalEncoding(nn.Module):
    def __init__(self, embed_dim, max_len=5000):
        super(PositionalEncoding, self).__init__()
        self.encoding = torch.zeros(max_len, embed_dim)
        positions = torch.arange(0, max_len).unsqueeze(1).float()
        div_term = torch.exp(torch.arange(0, embed_dim, 2).float() * -(math.log(10000.0) / embed_dim))
        self.encoding[:, 0::2] = torch.sin(positions * div_term)
        self.encoding[:, 1::2] = torch.cos(positions * div_term)
        self.encoding = self.encoding.unsqueeze(0)  # Shape (1, max_len, embed_dim)

    def forward(self, x):
        return x + self.encoding[:, :x.size(1)].detach()

class TimeSeriesDataset(Dataset):
    def __init__(self, data):
        self.scaler = StandardScaler()
        self.data = self.scaler.fit_transform(data.reshape(-1, data.shape[-1])).reshape(data.shape)
        self.data = torch.tensor(self.data, dtype=torch.float32)

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        return self.data[idx]

def load_model(model_path, input_size, embed_dim, num_heads, num_layers, dim_feedforward, dropout, device):
    model = TimeSeriesTransformer(
        input_size=input_size, embed_dim=embed_dim, num_heads=num_heads,
        num_layers=num_layers, dim_feedforward=dim_feedforward,
        dropout=dropout
    ).to(device)
    model.load_state_dict(torch.load(model_path, map_location=device), strict=False)
    model.eval()
    return model

def preprocess_data(data):
    data_array = np.array(data, dtype=np.float32)
    if len(data_array.shape) == 2:
        data_array = data_array[None, :, :]  # Add batch dimension if missing
    elif len(data_array.shape) != 3 or data_array.shape[2] != 8:
        raise ValueError("Data shape must be (batch_size, seq_len, 8)")

    dataset = TimeSeriesDataset(data_array)
    return DataLoader(dataset, batch_size=1, shuffle=False)

def predict(model, data_loader, device):
    model.eval()
    probabilities = []
    with torch.no_grad():
        for data in data_loader:
            data = data.to(device)
            output = model(data)
            probabilities.append(output.cpu().numpy())
    return np.concatenate(probabilities, axis=0)

def prediction2result(probabilities):
    cheating_prob = probabilities[0, 0]  # Assumes single sample; adjust if batch_size > 1
    return cheating_prob

# Initialize Flask app
app = Flask(__name__)

# Hardcoded paths and parameters
MODEL_PATH = './best_model.pth'
INPUT_SIZE = 8
EMBED_DIM = 32
NUM_HEADS = 2
NUM_LAYERS = 3
DIM_FEEDFORWARD = 64
DROPOUT = 0.1561791975716901

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model = load_model(
    model_path=MODEL_PATH,
    input_size=INPUT_SIZE,
    embed_dim=EMBED_DIM,
    num_heads=NUM_HEADS,
    num_layers=NUM_LAYERS,
    dim_feedforward=DIM_FEEDFORWARD,
    dropout=DROPOUT,
    device=device
)

@app.route('/predict', methods=['POST'])
def predict_api():
    data = request.json
    if not data or 'data' not in data:
        return jsonify({'error': 'No data provided'}), 400

    try:
        data_array = np.array(data['data'], dtype=np.float32)
        if len(data_array.shape) == 2:
            data_array = data_array[None, :, :]  # Add batch dimension if missing
        elif len(data_array.shape) != 3 or data_array.shape[2] != 8:
            raise ValueError("Data shape must be (batch_size, seq_len, 8)")

        data_loader = preprocess_data(data_array)
        probabilities = predict(model, data_loader, device)
        cheating_prob = prediction2result(probabilities)
        return jsonify({'probability_of_cheating': round(cheating_prob, 4)})
    except Exception as e:
        return jsonify({'error': str(e)}), 500

if __name__ == "__main__":
    app.run(debug=True)
