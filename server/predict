import torch
import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler
from torch.utils.data import Dataset, DataLoader
import math
import torch.nn as nn

# Define the Transformer model and other components
class TimeSeriesTransformer(nn.Module):
    def __init__(self, input_size, embed_dim, num_heads, num_layers, dim_feedforward, dropout):
        super(TimeSeriesTransformer, self).__init__()
        assert embed_dim % num_heads == 0, "embed_dim must be divisible by num_heads"

        self.embedding = nn.Linear(input_size, embed_dim)
        self.positional_encoding = PositionalEncoding(embed_dim)
        self.transformer = nn.Transformer(
            d_model=embed_dim,
            nhead=num_heads,
            num_encoder_layers=num_layers,
            num_decoder_layers=num_layers,
            dim_feedforward=dim_feedforward,
            dropout=dropout
        )
        self.fc = nn.Linear(embed_dim, 2)
        self.softmax = nn.Softmax(dim=1)  # Softmax to get probabilities

    def forward(self, x):
        x = self.embedding(x)
        x = self.positional_encoding(x)
        x = x.permute(1, 0, 2)  # Transformer expects (seq_len, batch, embed_dim)
        output = self.transformer(x, x)
        output = output[-1, :, :]  # Take the output of the last time step
        output = self.fc(output)
        output = self.softmax(output)  # Apply softmax to get probabilities
        return output

class PositionalEncoding(nn.Module):
    def __init__(self, embed_dim, max_len=5000):
        super(PositionalEncoding, self).__init__()
        self.encoding = torch.zeros(max_len, embed_dim)
        positions = torch.arange(0, max_len).unsqueeze(1).float()
        div_term = torch.exp(torch.arange(0, embed_dim, 2).float() * -(math.log(10000.0) / embed_dim))
        self.encoding[:, 0::2] = torch.sin(positions * div_term)
        self.encoding[:, 1::2] = torch.cos(positions * div_term)
        self.encoding = self.encoding.unsqueeze(0)  # Shape (1, max_len, embed_dim)

    def forward(self, x):
        return x + self.encoding[:, :x.size(1)].detach()

class TimeSeriesDataset(Dataset):
    def __init__(self, data):
        self.scaler = StandardScaler()
        self.data = self.scaler.fit_transform(data)
        self.data = torch.tensor(self.data, dtype=torch.float32)

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        return self.data[idx]

def load_model(model_path, input_size, embed_dim, num_heads, num_layers, dim_feedforward, dropout, device):
    model = TimeSeriesTransformer(
        input_size=input_size, embed_dim=embed_dim, num_heads=num_heads,
        num_layers=num_layers, dim_feedforward=dim_feedforward,
        dropout=dropout
    ).to(device)
    model.load_state_dict(torch.load(model_path, map_location=device), strict=False)
    model.eval()
    return model

def preprocess_data(file_path):
    data = pd.read_csv(file_path).values.astype(np.float32)
    dataset = TimeSeriesDataset(data)
    return DataLoader(dataset, batch_size=1, shuffle=False)

def predict(model, data_loader, device):
    model.eval()
    probabilities = []
    with torch.no_grad():
        for data in data_loader:
            data = data.to(device)
            output = model(data)
            probabilities.append(output.cpu().numpy())
    return np.concatenate(probabilities, axis=0)

def prediction2result(probabilities):
    # Extract probability of 'Cheating' (class 0)
    cheating_prob = probabilities[0, 0]  # Assumes single sample; adjust if batch_size > 1
    return cheating_prob

def main():
    # Hardcoded paths and parameters
    model_path = 'path/to/model.pth'
    data_path = 'path/to/data.csv'
    input_size = 8
    embed_dim = 32
    num_heads = 2
    num_layers = 3
    dim_feedforward = 64
    dropout = 0.1561791975716901

    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

    model = load_model(
        model_path=model_path,
        input_size=input_size,
        embed_dim=embed_dim,
        num_heads=num_heads,
        num_layers=num_layers,
        dim_feedforward=dim_feedforward,
        dropout=dropout,
        device=device
    )
    data_loader = preprocess_data(data_path)
    probabilities = predict(model, data_loader, device)

    cheating_prob = prediction2result(probabilities)
    print(f"Probability of Cheating: {cheating_prob:.4f}")

if __name__ == "__main__":
    main()
